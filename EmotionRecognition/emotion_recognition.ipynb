{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " emotion_recognition.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMUhQHaxkJcEefWiTT3XcPW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KumundzhievMaxim/AppliedDeepLearning/blob/main/EmotionRecognition/emotion_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDVZ9bm8R7d5"
      },
      "source": [
        "### Downloading the Data {When UNI Link unreacheable}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_Po5yhnOWDO",
        "outputId": "f302cb76-bb1e-4821-d12d-fe507d481e3d"
      },
      "source": [
        "# Audio Song 1-24\n",
        "!wget -O Audio_Song_Actors_01-24.zip https://zenodo.org/record/1188976/files/Audio_Song_Actors_01-24.zip?download=1 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-15 07:30:35--  https://zenodo.org/record/1188976/files/Audio_Song_Actors_01-24.zip?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 225505317 (215M) [application/octet-stream]\n",
            "Saving to: ‘Audio_Song_Actors_01-24.zip’\n",
            "\n",
            "Audio_Song_Actors_0 100%[===================>] 215.06M  7.43MB/s    in 31s     \n",
            "\n",
            "2020-12-15 07:31:07 (7.04 MB/s) - ‘Audio_Song_Actors_01-24.zip’ saved [225505317/225505317]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgSC41c5PS8w",
        "outputId": "a38cfc0e-a9b6-4fdf-80af-e3fda36d21ec"
      },
      "source": [
        "# Audio Speech\n",
        "!wget -O Audio_Speech_Actors_01-24.zip https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip?download=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-15 07:31:57--  https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 208468073 (199M) [application/octet-stream]\n",
            "Saving to: ‘Audio_Speech_Actors_01-24.zip’\n",
            "\n",
            "Audio_Speech_Actors 100%[===================>] 198.81M  8.33MB/s    in 27s     \n",
            "\n",
            "2020-12-15 07:32:25 (7.41 MB/s) - ‘Audio_Speech_Actors_01-24.zip’ saved [208468073/208468073]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYPVmyCtPk51",
        "outputId": "6b1f9e2c-4f60-4797-fda1-48e79225b034"
      },
      "source": [
        "# Unzip Audio Song 1-24 (./song)\n",
        "!mkdir ./song && unzip /content/Audio_Song_Actors_01-24.zip -d ./song && rm -r /content/Audio_Song_Actors_01-24.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./song’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMr99_zxP-_Q"
      },
      "source": [
        "# Unzip Audio Speech 1-24 (./speech)\n",
        "!mkdir ./speech && unzip -q /content/Audio_Speech_Actors_01-24.zip -d ./speech  && rm -r /content/Audio_Speech_Actors_01-24.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvWdh4oXT_2k",
        "outputId": "29dbb4ad-4d92-46f4-b07f-8de6c3b0ac54"
      },
      "source": [
        "# Downalod Video Song Actor 1-9\n",
        "import os\n",
        "\n",
        "for video_index in range(1, 10):\n",
        "  down_cmd = f'wget -O Video_Song_Actor_0{video_index}.zip https://zenodo.org/record/1188976/files/Video_Song_Actor_0{video_index}.zip?download=1'\n",
        "  dir_cmd = f'mkdir ./video/Actor_0{video_index}'\n",
        "  unzip_cmd = f'unzip -q Video_Song_Actor_0{video_index}.zip -d ./video/Actor_0{video_index}/'\n",
        "  rm_cmd = f'rm -r Video_Song_Actor_0{video_index}.zip'\n",
        "\n",
        "  print(f'Downloading Video_{video_index} zip')\n",
        "  os.system(down_cmd)\n",
        "  \n",
        "  print('Created folder for particular Video zip')\n",
        "  os.system(dir_cmd)\n",
        "  \n",
        "  print('Unzipping particular Video')\n",
        "  os.system(unzip_cmd)\n",
        "\n",
        "  print('Deleting particular Video zip')\n",
        "  os.system(rm_cmd)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Video_1 zip\n",
            "Created folder for particular Video zip\n",
            "Unzipping particular Video\n",
            "Deleting particular Video zip\n",
            "Downloading Video_2 zip\n",
            "Created folder for particular Video zip\n",
            "Unzipping particular Video\n",
            "Deleting particular Video zip\n",
            "Downloading Video_3 zip\n",
            "Created folder for particular Video zip\n",
            "Unzipping particular Video\n",
            "Deleting particular Video zip\n",
            "Downloading Video_4 zip\n",
            "Created folder for particular Video zip\n",
            "Unzipping particular Video\n",
            "Deleting particular Video zip\n",
            "Downloading Video_5 zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jU4RO-dlnW5"
      },
      "source": [
        "# ENTRY POINT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBv5dryRVWXV"
      },
      "source": [
        "## Data Description\n",
        "The RAVDESS contains **7356** files. \n",
        "Each file was rated **10 times** on emotional validity, intensity, and genuineness\n",
        "\n",
        "[Video example](https://www.youtube.com/watch?v=Y7OQoNEu3dY)\n",
        "\n",
        "The database contains 24 professional actors (12 female, 12 male), vocalizing two lexically-matched statements in a neutral North American accent. Speech includes calm, happy, sad, angry, fearful, surprise, and disgust expressions.\n",
        "\n",
        "\n",
        "All conditions are available in three modality formats: Audio-only (16bit, 48kHz .wav), Audio-Video (720p H.264, AAC 48kHz, .mp4), and Video-only (no sound).  <b>Note, there are no song files for Actor_18.</b>\n",
        "\n",
        "\n",
        "### Names convetions and details\n",
        "#### Audio-only files {Audio_Speech_Actors}\n",
        "Audio-only files of all actors (01-24) are available as two separate zip files (~200 MB each):\n",
        "\n",
        "Speech file (Audio_Speech_Actors_01-24.zip, 215 MB) contains 1440 files: 60 trials per actor x 24 actors = 1440. \n",
        "\n",
        "#### Audio-Visual and Video-only files files {Video_Speech_Actor}\n",
        "Speech files (Video_Speech_Actor_01.zip to Video_Speech_Actor_24.zip) collectively contains 2880 files: 60 trials per actor x 2 modalities (AV, VO) x 24 actors = 2880.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEqbfYEvXNm-"
      },
      "source": [
        "### Download Data when UNI Link reachable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAM4xOIHWN9s",
        "outputId": "94c7e29e-7f08-4e7d-a72b-fdc6f6ca9f52"
      },
      "source": [
        "!wget -O ravdess.zip http://nipg1.inf.elte.hu:8765/ravdess.zip "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-15 14:52:48--  http://nipg1.inf.elte.hu:8765/ravdess.zip\n",
            "Resolving nipg1.inf.elte.hu (nipg1.inf.elte.hu)... 157.181.160.161\n",
            "Connecting to nipg1.inf.elte.hu (nipg1.inf.elte.hu)|157.181.160.161|:8765... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13565818088 (13G) [application/zip]\n",
            "Saving to: ‘ravdess.zip’\n",
            "\n",
            "ravdess.zip         100%[===================>]  12.63G  16.2MB/s    in 11m 44s \n",
            "\n",
            "2020-12-15 15:04:33 (18.4 MB/s) - ‘ravdess.zip’ saved [13565818088/13565818088]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGyt6elQXWCk"
      },
      "source": [
        "!unzip -q ravdess.zip "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47Enkvgsox0O"
      },
      "source": [
        "### HERE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxie6OnLJ8Z7",
        "outputId": "811fc0c3-180c-405a-9291-b770414ae6e7"
      },
      "source": [
        "!pip install librosa soundfile pyaudio"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Collecting pyaudio\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/42/b4f04721c5c5bfc196ce156b3c768998ef8c0ae3654ed29ea5020c749a6b/PyAudio-0.2.11.tar.gz\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.48.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.15.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.17.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.4)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (50.3.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Building wheels for collected packages: pyaudio\n",
            "  Building wheel for pyaudio (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for pyaudio\n",
            "Failed to build pyaudio\n",
            "Installing collected packages: soundfile, pyaudio\n",
            "    Running setup.py install for pyaudio ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-jq18odkv/pyaudio/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-jq18odkv/pyaudio/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-l2sgga5b/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6J8zoMRJ4Cr"
      },
      "source": [
        "# imports\n",
        "import random\n",
        "from tqdm import tqdm \n",
        "from typing import List\n",
        "import os, glob, pickle\n",
        "from pathlib import Path\n",
        "\n",
        "import librosa\n",
        "import soundfile\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5wh7CKaQx6c"
      },
      "source": [
        "## Audio Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx-u5nMwjoED"
      },
      "source": [
        "# utils\n",
        "\n",
        "emotions={\n",
        "    '01':'neutral',\n",
        "    '02':'calm',\n",
        "    '03':'happy',\n",
        "    '04':'sad',\n",
        "    '05':'angry',\n",
        "    '06':'fearful',\n",
        "    '07':'disgust',\n",
        "    '08':'surprised'\n",
        "    }\n",
        "\n",
        "# Emotions to observe\n",
        "observed_emotions=['calm', 'happy', 'fearful', 'disgust']\n",
        "\n",
        "\n",
        "def extract_feature(file_name, mfcc, chroma, mel):\n",
        "  with soundfile.SoundFile(file_name) as sound_file:\n",
        "      X = sound_file.read(dtype=\"float32\")\n",
        "      sample_rate=sound_file.samplerate\n",
        "      if chroma:\n",
        "          stft=np.abs(librosa.stft(X))\n",
        "      result=np.array([])\n",
        "      if mfcc:\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "        mfccs = np.std(mfccs)\n",
        "        result=np.hstack((result, mfccs))\n",
        "      if chroma:\n",
        "        chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "        chroma=np.std(chroma)\n",
        "        result=np.hstack((result, chroma))\n",
        "      if mel:\n",
        "        mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "        mel=np.std(mel)\n",
        "        result=np.hstack((result, mel))\n",
        "  return result\n",
        "\n",
        "\n",
        "# load data\n",
        "def load_data(test_size=0.2):\n",
        "  x,y=[],[]\n",
        "  for file in glob.glob(f\"{ROOT_SPEECH}/**/*.wav\"):\n",
        "    try:\n",
        "      file_name=os.path.basename(file)\n",
        "      emotion=emotions[file_name.split(\"-\")[2]]\n",
        "      if emotion not in observed_emotions:\n",
        "        continue\n",
        "      feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "      x.append(feature)\n",
        "      y.append(emotion)\n",
        "    except Exception as e:\n",
        "      print(f'Unvalidated speech record: {file}')\n",
        "      continue\n",
        "\n",
        "  return train_test_split(np.array(x), y, test_size=test_size, random_state=9)\n",
        "    "
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1rpfYiwo4sN",
        "outputId": "cf2e9228-dd06-4113-a36f-f3533f1db12e"
      },
      "source": [
        "# --main\n",
        "ROOT = './ravdess'\n",
        "ROOT_SPEECH = './speech'\n",
        "\n",
        "# unzip Speech Actors\n",
        "Path(ROOT_SPEECH).mkdir(exist_ok=True)\n",
        "unzip_cmd = f'unzip {ROOT}/Audio_Speech_Actors_01-24.zip -d ./speech/'\n",
        "os.system(unzip_cmd)\n",
        "\n",
        "x_train, x_test, y_train, y_test = load_data(test_size=0.25)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unvalidated speech record: ./speech/Actor_05/03-01-02-01-02-02-05.wav\n",
            "Unvalidated speech record: ./speech/Actor_01/03-01-02-01-01-02-01.wav\n",
            "Unvalidated speech record: ./speech/Actor_20/03-01-06-01-01-02-20.wav\n",
            "Unvalidated speech record: ./speech/Actor_20/03-01-03-01-02-01-20.wav\n",
            "(573, 191)\n",
            "Features extracted: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPyW86poQ2-L",
        "outputId": "6baac337-5c30-41b4-b885-4aca2412a785"
      },
      "source": [
        "print(x_train[0]) # track data"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.27670344e+02 4.16242368e-02 1.07234560e-03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mzu8kJ3UQ-69"
      },
      "source": [
        "## Video Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nFUvimFXESe"
      },
      "source": [
        "# utils\n",
        "def _unzip(path: List[str]):\n",
        "  unzipped_folders = []\n",
        "\n",
        "  target = Path(ROOT_DIR, 'videos')\n",
        "  target.mkdir(exist_ok=True)\n",
        "\n",
        "  for video_index, video_zip in enumerate(path):  \n",
        "    source = f'{ROOT_DIR}/{video_zip}'\n",
        "    print(f'Unzip {source} TO {target}')\n",
        "\n",
        "    unzip_cmd = f'unzip -q {source} -d {target} &' # umpersant relies for continue of the execution, otherwise STOPS. \n",
        "    os.system(unzip_cmd)\n",
        "    unzipped_folders.append(Path(target, f'Actor_{video_zip.split(\"_\")[3].replace(\".zip\", \"\")}'))\n",
        "  return unzipped_folders\n",
        "\n",
        "def extract_faces(paths):\n",
        "  Path('./video_faces/').mkdir(exist_ok=True)\n",
        "  for folder in unzipped_folders:\n",
        "    fc = 0\n",
        "    ret = True\n",
        "    videos = [file for file in os.listdir(folder)]\n",
        "\n",
        "    # define detector\n",
        "    face_cs = cv2.CascadeClassifier()\n",
        "    face_cs = face_cs.load(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    r_frames = [random.randint(0, 20) for _ in range(6)]\n",
        "    for k in range(len(videos)):\n",
        "      cap = cv2.VideoCapture(videos[k])\n",
        "      num, count = 16, 6\n",
        "      width, height = 64, 64\n",
        "\n",
        "      buff = np.empty((count, height, width, 3), np.dtype('uint8'))\n",
        "      all_frames = np.empty((num, height, width, 3), np.dtype('uint8'))\n",
        "      print(cap)\n",
        "\n",
        "      while (fc < num and ret):\n",
        "          ret, original_frame = cap.read()\n",
        "          original_frame = cv2.cvtColor(original_frame, cv2.COLOR_RGB2BGR)\n",
        "          if ret:\n",
        "            #get face\n",
        "            _frame = cv2.cvtColor(original_frame, cv2.COLOR_BGR2GRAY)\n",
        "            face = face_cascade.detectMultiScale(_frame)\n",
        "            if len(face) > 0:\n",
        "              face = face[0]\n",
        "              x, y, w, h = [v for v in face]\n",
        "              cropped_face = original_frame[y:y+h, x:x+w]\n",
        "              all_frames[fc] = cv2.resize(cropped_face,(64,64))\n",
        "              fc += 1\n",
        "                \n",
        "      for i in range(len(r_frames)):\n",
        "          buff[i] = all_frames[r_frames[i]]\n",
        "        \n",
        "      cap.release()\n",
        "      f = open(\"./\" + pkl_dir+fnames[k][9:-4] + \".pkl\", 'wb')\n",
        "      pickle.dump(buff, f)\n",
        "      f.close()\n",
        "  return True  "
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBdy_75KRBuP",
        "outputId": "f2549765-626d-438f-db68-7bbf3c66ee88"
      },
      "source": [
        "# --main\n",
        "ROOT_DIR = './ravdess'\n",
        "ROOT_VIDEOS = './ravdess/videos'\n",
        "\n",
        "video_zips = sorted([zip_name for zip_name in os.listdir(ROOT_DIR) if zip_name.startswith('Video')])  \n",
        "\n",
        "TOY_TARGET = video_zips[0]\n",
        "\n",
        "unzipped_folders = _unzip([TOY_TARGET])\n",
        "extract_faces(unzipped_folders) "
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unzip ./ravdess/Video_Speech_Actor_01.zip TO ravdess/videos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS_fOpylQttU"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nze8ylptKRbv",
        "outputId": "0f243496-a589-452f-d8df-68d0be4194f6"
      },
      "source": [
        "# Audio Model\n",
        "\n",
        "# Input\n",
        "video_input = Input(shape=(24,171,1))\n",
        "\n",
        "x = Conv2D(32, (3, 3),padding=\"same\", activation='relu', input_shape=(24, 171, 1))(video_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = ReLU()(x)\n",
        "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
        "x = Conv2D(32, (3, 3),padding=\"same\", activation='relu', input_shape=(24, 171, 1))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = ReLU()(x)\n",
        "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Output\n",
        "video_output = Dense(128,activation='relu')(x)\n",
        "\n",
        "video_model = Model(video_input, video_output)\n",
        "video_model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy']) \n",
        "video_model.summary()"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 24, 171, 1)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 24, 171, 32)       320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 24, 171, 32)       128       \n",
            "_________________________________________________________________\n",
            "re_lu_10 (ReLU)              (None, 24, 171, 32)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 12, 86, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 12, 86, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 12, 86, 32)        128       \n",
            "_________________________________________________________________\n",
            "re_lu_11 (ReLU)              (None, 12, 86, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 6, 43, 32)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 8256)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               1056896   \n",
            "=================================================================\n",
            "Total params: 1,066,720\n",
            "Trainable params: 1,066,592\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbB8Qy3rPOOz",
        "outputId": "d5eb2573-72dc-4d91-eca7-b6dc51bb7ba8"
      },
      "source": [
        "# Audio Model\n",
        "\n",
        "# Input\n",
        "audio_input = Input(shape=(6,64,64,3))\n",
        "\n",
        "x = TimeDistributed(Conv2D(32, (3,3), padding='same', strides=(2,2), activation='relu'))(audio_input)\n",
        "x = TimeDistributed(Conv2D(32, (3,3), padding='same', strides=(2,2), activation='relu'))(x)\n",
        "x = TimeDistributed(MaxPooling2D((2,2), strides=(2,2)))(x)\n",
        "x = TimeDistributed(Conv2D(32, (3,3), padding='same', strides=(2,2), activation='relu'))(x)\n",
        "x = TimeDistributed(Conv2D(32, (3,3), padding='same', strides=(2,2), activation='relu'))(x)\n",
        "x = TimeDistributed(MaxPooling2D((2,2), strides=(2,2)))(x)\n",
        "x = TimeDistributed(GlobalMaxPooling2D())(x)\n",
        "\n",
        "# Output\n",
        "audio_output = LSTM(32, activation='relu', return_sequences=False)(x)\n",
        "\n",
        "audio_model = Model(audio_input, audio_output)\n",
        "audio_model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy']) \n",
        "audio_model.summary()"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 6, 64, 64, 3)]    0         \n",
            "_________________________________________________________________\n",
            "time_distributed_35 (TimeDis (None, 6, 32, 32, 32)     896       \n",
            "_________________________________________________________________\n",
            "time_distributed_36 (TimeDis (None, 6, 16, 16, 32)     9248      \n",
            "_________________________________________________________________\n",
            "time_distributed_37 (TimeDis (None, 6, 8, 8, 32)       0         \n",
            "_________________________________________________________________\n",
            "time_distributed_38 (TimeDis (None, 6, 4, 4, 32)       9248      \n",
            "_________________________________________________________________\n",
            "time_distributed_39 (TimeDis (None, 6, 2, 2, 32)       9248      \n",
            "_________________________________________________________________\n",
            "time_distributed_40 (TimeDis (None, 6, 1, 1, 32)       0         \n",
            "_________________________________________________________________\n",
            "time_distributed_41 (TimeDis (None, 6, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 32)                8320      \n",
            "=================================================================\n",
            "Total params: 36,960\n",
            "Trainable params: 36,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hnfQSqWfBgZ"
      },
      "source": [
        "## Model Fusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARcylAlJfElV"
      },
      "source": [
        "from tensorflow.keras.layers import Concatenate\n",
        "\n",
        "fusion_concat = Concatenate([audio_model, video_model])\n",
        "input_size = [audio_input, video_input]\n",
        "\n",
        "h1 = Dense(256, activation='relu')(fusion_concat)\n",
        "h2 = Dense(7, activation='softmax')(h1)\n",
        "\n",
        "model = Model(input_size, h2)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3FMRn7hgEYt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}